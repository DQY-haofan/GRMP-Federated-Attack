2025-10-30 00:19:36.219641: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2025-10-30 00:19:36.237458: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1761783576.259223    4171 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1761783576.265811    4171 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered W0000 00:00:1761783576.282269    4171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1761783576.282299    4171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1761783576.282303    4171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1761783576.282305    4171 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. 2025-10-30 00:19:36.287226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations. To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. Progressive GRMP (Graph Representation-based Model Poisoning) Attack Target: AG News Classification - Business+Finance → Sports Strategy: Gradual poisoning intensity to evade detection ================================================== Setting up Progressive GRMP Attack Experiment ================================================== tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 303kB/s] vocab.txt: 100% 232k/232k [00:00<00:00, 1.08MB/s] tokenizer.json: 100% 466k/466k [00:00<00:00, 38.0MB/s] config.json: 100% 483/483 [00:00<00:00, 3.31MB/s] Loading AG News dataset (direct download)... Downloading training data... Downloading test data... Dataset loaded! Train: 3000 samples, Test: 1000 samples Train distribution: {'World': np.int64(736), 'Sports': np.int64(794), 'Business': np.int64(713), 'Sci/Tech': np.int64(757)} Test distribution: {'World': np.int64(236), 'Sports': np.int64(242), 'Business': np.int64(245), 'Sci/Tech': np.int64(277)} Partitioning data among clients... Attack test set: 117 Business articles with financial keywords Initializing global model... model.safetensors: 100% 268M/268M [00:01<00:00, 140MB/s] Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight'] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. Creating federated learning clients... Client 0 (Benign) - Distribution: {'World': np.int64(119), 'Sports': np.int64(131), 'Business': np.int64(121), 'Sci/Tech': np.int64(129)} Client 1 (Benign) - Distribution: {'World': np.int64(135), 'Sports': np.int64(121), 'Business': np.int64(117), 'Sci/Tech': np.int64(127)} Client 2 (Benign) - Distribution: {'World': np.int64(108), 'Sports': np.int64(139), 'Business': np.int64(115), 'Sci/Tech': np.int64(138)} Client 3 (Benign) - Distribution: {'World': np.int64(144), 'Sports': np.int64(132), 'Business': np.int64(114), 'Sci/Tech': np.int64(110)} Client 4 (Attacker) - Will use progressive poisoning Round 0 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=160.0%): 67/67 samples poisoned Client 5 (Attacker) - Will use progressive poisoning Round 0 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=160.0%): 62/62 samples poisoned Evaluating initial model... Initial Performance - Clean: 0.2800, ASR: 0.0000 ================================================== Starting Progressive Federated Learning Attack ================================================== ============================================================ Round 1/20 Attack Stage: 🌱 Early Stage (Building trust) Current Parameters: server_lr=0.80, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 0 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=160.0%): 67/67 samples poisoned Round 0 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=160.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training  ✓ Client 4 completed training  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.901 ± 0.003    Attacker 4 - Round 0:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.7797 -> 1.5815    Direction preservation 方向保持: 0.9860    Final similarity 最终相似度: 0.8174 (目标: 0.900)    Difference from benign mean 与良性均值差异: 0.084    Benign user similarity: 0.901 ± 0.003    Attacker 5 - Round 0:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.8055 -> 1.6322    Direction preservation 方向保持: 0.9870    Final similarity 最终相似度: 0.8170 (目标: 0.900)    Difference from benign mean 与良性均值差异: 0.084 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.792, Std Dev: 0.015    Client 0 (Benign): 0.782    Client 1 (Benign): 0.781    Client 2 (Benign): 0.770    Client 3 (Benign): 0.802    Client 4 (Attacker): 0.807    Client 5 (Attacker): 0.807  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.7624  Rejection Rate: 0.0% 📊 Round 1 Results:  Clean Accuracy: 0.8300  Attack Success Rate: 0.0000 ============================================================ Round 2/20 Attack Stage: 🌱 Early Stage (Building trust) Current Parameters: server_lr=0.80, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 1 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=160.0%): 67/67 samples poisoned Round 1 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=160.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.768 ± 0.021    Attacker 4 - Round 1:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.6177 -> 1.2580    Direction preservation 方向保持: 0.9821    Final similarity 最终相似度: 0.4775 (目标: 0.757)    Difference from benign mean 与良性均值差异: 0.290    Benign user similarity: 0.768 ± 0.021    Attacker 5 - Round 1:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.6427 -> 1.3068    Direction preservation 方向保持: 0.9835    Final similarity 最终相似度: 0.4877 (目标: 0.757)    Difference from benign mean 与良性均值差异: 0.280 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.518, Std Dev: 0.046    Client 0 (Benign): 0.487    Client 1 (Benign): 0.549    Client 2 (Benign): 0.484    Client 3 (Benign): 0.451    Client 4 (Attacker): 0.566    Client 5 (Attacker): 0.573  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.4254  Rejection Rate: 0.0% 📊 Round 2 Results:  Clean Accuracy: 0.8730  Attack Success Rate: 0.0000 ============================================================ Round 3/20 Attack Stage: 🌱 Early Stage (Building trust) Current Parameters: server_lr=0.80, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 2 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=160.0%): 67/67 samples poisoned Round 2 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=160.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.624 ± 0.015    Attacker 4 - Round 2:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.4807 -> 0.9801    Direction preservation 方向保持: 0.9810    Final similarity 最终相似度: 0.1503 (目标: 0.616)    Difference from benign mean 与良性均值差异: 0.474    Benign user similarity: 0.624 ± 0.015    Attacker 5 - Round 2:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.4977 -> 1.0134    Direction preservation 方向保持: 0.9823    Final similarity 最终相似度: 0.1641 (目标: 0.616)    Difference from benign mean 与良性均值差异: 0.460 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.288, Std Dev: 0.074    Client 0 (Benign): 0.218    Client 1 (Benign): 0.304    Client 2 (Benign): 0.238    Client 3 (Benign): 0.204    Client 4 (Attacker): 0.379    Client 5 (Attacker): 0.387  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.1404  Rejection Rate: 0.0% 📊 Round 3 Results:  Clean Accuracy: 0.8850  Attack Success Rate: 0.0000 ============================================================ Round 4/20 Attack Stage: 🌱 Early Stage (Building trust) Current Parameters: server_lr=0.80, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 3 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=200.0%): 67/67 samples poisoned Round 3 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=200.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.571 ± 0.013    Attacker 4 - Round 3:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.4133 -> 0.8474    Direction preservation 方向保持: 0.9755    Final similarity 最终相似度: 0.0651 (目标: 0.565)    Difference from benign mean 与良性均值差异: 0.506    Benign user similarity: 0.571 ± 0.013    Attacker 5 - Round 3:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.4183 -> 0.8571    Direction preservation 方向保持: 0.9761    Final similarity 最终相似度: 0.1040 (目标: 0.565)    Difference from benign mean 与良性均值差异: 0.467 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.225, Std Dev: 0.080    Client 0 (Benign): 0.157    Client 1 (Benign): 0.262    Client 2 (Benign): 0.155    Client 3 (Benign): 0.134    Client 4 (Attacker): 0.312    Client 5 (Attacker): 0.333  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 4 Results:  Clean Accuracy: 0.8950  Attack Success Rate: 0.0085 ============================================================ Round 5/20 Attack Stage: 🌱 Early Stage (Building trust) Current Parameters: server_lr=0.80, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 4 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=200.0%): 67/67 samples poisoned Round 4 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=200.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.561 ± 0.014    Attacker 4 - Round 4:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.3791 -> 0.7808    Direction preservation 方向保持: 0.9710    Final similarity 最终相似度: 0.0087 (目标: 0.554)    Difference from benign mean 与良性均值差异: 0.552    Benign user similarity: 0.561 ± 0.014    Attacker 5 - Round 4:    Amplification factor 放大因子: 2.0, beta: 0.3    Norm 规范: 0.3814 -> 0.7827    Direction preservation 方向保持: 0.9746    Final similarity 最终相似度: 0.0215 (目标: 0.554)    Difference from benign mean 与良性均值差异: 0.539 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.190, Std Dev: 0.050    Client 0 (Benign): 0.129    Client 1 (Benign): 0.181    Client 2 (Benign): 0.134    Client 3 (Benign): 0.188    Client 4 (Attacker): 0.248    Client 5 (Attacker): 0.257  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0903  Rejection Rate: 0.0% 📊 Round 5 Results:  Clean Accuracy: 0.8970  Attack Success Rate: 0.0171 ============================================================ Round 6/20 Attack Stage: 🌿 Growth Stage (Gradual enhancement) Current Parameters: server_lr=0.80, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 5 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 5 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.562 ± 0.007    Attacker 4 - Round 5:    Amplification factor 放大因子: 2.3, beta: 0.4    Norm 规范: 0.3588 -> 0.8606    Direction preservation 方向保持: 0.9589    Final similarity 最终相似度: -0.0093 (目标: 0.555)    Difference from benign mean 与良性均值差异: 0.571    Benign user similarity: 0.562 ± 0.007    Attacker 5 - Round 5:    Amplification factor 放大因子: 2.3, beta: 0.4    Norm 规范: 0.3590 -> 0.8611    Direction preservation 方向保持: 0.9589    Final similarity 最终相似度: 0.0178 (目标: 0.555)    Difference from benign mean 与良性均值差异: 0.544 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.185, Std Dev: 0.071    Client 0 (Benign): 0.119    Client 1 (Benign): 0.108    Client 2 (Benign): 0.114    Client 3 (Benign): 0.267    Client 4 (Attacker): 0.243    Client 5 (Attacker): 0.257  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 6 Results:  Clean Accuracy: 0.8890  Attack Success Rate: 0.0085 ============================================================ Round 7/20  🔄 System stable. Increasing server learning rate to: 0.88 Attack Stage: 🌿 Growth Stage (Gradual enhancement) Current Parameters: server_lr=0.88, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 6 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 6 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.568 ± 0.014    Attacker 4 - Round 6:    Amplification factor 放大因子: 2.5, beta: 0.4    Norm 规范: 0.3482 -> 0.9052    Direction preservation 方向保持: 0.9654    Final similarity 最终相似度: -0.0465 (目标: 0.554)    Difference from benign mean 与良性均值差异: 0.615    Benign user similarity: 0.568 ± 0.014    Attacker 5 - Round 6:    Amplification factor 放大因子: 2.5, beta: 0.4    Norm 规范: 0.3496 -> 0.9088    Direction preservation 方向保持: 0.9656    Final similarity 最终相似度: -0.0180 (目标: 0.554)    Difference from benign mean 与良性均值差异: 0.586 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.172, Std Dev: 0.062    Client 0 (Benign): 0.115    Client 1 (Benign): 0.105    Client 2 (Benign): 0.115    Client 3 (Benign): 0.252    Client 4 (Attacker): 0.216    Client 5 (Attacker): 0.231  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.8800000000000001 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 7 Results:  Clean Accuracy: 0.8910  Attack Success Rate: 0.0427 ============================================================ Round 8/20  🔄 System stable. Increasing server learning rate to: 0.95 Attack Stage: 🌿 Growth Stage (Gradual enhancement) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 7 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 7 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.583 ± 0.008    Attacker 4 - Round 7:    Amplification factor 放大因子: 2.7, beta: 0.4    Norm 规范: 0.3887 -> 1.0584    Direction preservation 方向保持: 0.9757    Final similarity 最终相似度: -0.0527 (目标: 0.575)    Difference from benign mean 与良性均值差异: 0.636    Benign user similarity: 0.583 ± 0.008    Attacker 5 - Round 7:    Amplification factor 放大因子: 2.7, beta: 0.4    Norm 规范: 0.3926 -> 1.0686    Direction preservation 方向保持: 0.9761    Final similarity 最终相似度: -0.0287 (目标: 0.575)    Difference from benign mean 与良性均值差异: 0.612 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.169, Std Dev: 0.052    Client 0 (Benign): 0.117    Client 1 (Benign): 0.107    Client 2 (Benign): 0.133    Client 3 (Benign): 0.246    Client 4 (Attacker): 0.198    Client 5 (Attacker): 0.212  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 8 Results:  Clean Accuracy: 0.8850  Attack Success Rate: 0.1282 ============================================================ Round 9/20 Attack Stage: 🌿 Growth Stage (Gradual enhancement) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 8 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 8 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.578 ± 0.018    Attacker 4 - Round 8:    Amplification factor 放大因子: 2.8, beta: 0.4    Norm 规范: 0.4078 -> 1.1498    Direction preservation 方向保持: 0.9790    Final similarity 最终相似度: -0.0126 (目标: 0.560)    Difference from benign mean 与良性均值差异: 0.591    Benign user similarity: 0.578 ± 0.018    Attacker 5 - Round 8:    Amplification factor 放大因子: 2.8, beta: 0.4    Norm 规范: 0.4116 -> 1.1599    Direction preservation 方向保持: 0.9793    Final similarity 最终相似度: 0.0130 (目标: 0.560)    Difference from benign mean 与良性均值差异: 0.565 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.170, Std Dev: 0.036    Client 0 (Benign): 0.169    Client 1 (Benign): 0.125    Client 2 (Benign): 0.121    Client 3 (Benign): 0.192    Client 4 (Attacker): 0.200    Client 5 (Attacker): 0.214  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0978  Rejection Rate: 0.0% 📊 Round 9 Results:  Clean Accuracy: 0.8680  Attack Success Rate: 0.2308  ⚠️ ASR Change: +10.26% ============================================================ Round 10/20 Attack Stage: 🌿 Growth Stage (Gradual enhancement) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 9 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 9 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.594 ± 0.015    Attacker 4 - Round 9:    Amplification factor 放大因子: 2.8, beta: 0.4    Norm 规范: 0.4059 -> 1.1719    Direction preservation 方向保持: 0.9808    Final similarity 最终相似度: -0.0287 (目标: 0.579)    Difference from benign mean 与良性均值差异: 0.623    Benign user similarity: 0.594 ± 0.015    Attacker 5 - Round 9:    Amplification factor 放大因子: 2.8, beta: 0.4    Norm 规范: 0.4159 -> 1.1999    Direction preservation 方向保持: 0.9817    Final similarity 最终相似度: -0.0110 (目标: 0.579)    Difference from benign mean 与良性均值差异: 0.605 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.173, Std Dev: 0.045    Client 0 (Benign): 0.122    Client 1 (Benign): 0.125    Client 2 (Benign): 0.149    Client 3 (Benign): 0.246    Client 4 (Attacker): 0.193    Client 5 (Attacker): 0.205  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0833  Rejection Rate: 0.0% 📊 Round 10 Results:  Clean Accuracy: 0.8750  Attack Success Rate: 0.1795 ============================================================ Round 11/20 Attack Stage: 🌳 Mature Stage (Stable attacks) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 10 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 10 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.574 ± 0.008    Attacker 4 - Round 10:    Amplification factor 放大因子: 3.2, beta: 0.5    Norm 规范: 0.4025 -> 1.3121    Direction preservation 方向保持: 0.9762    Final similarity 最终相似度: -0.0215 (目标: 0.562)    Difference from benign mean 与良性均值差异: 0.596    Benign user similarity: 0.574 ± 0.008    Attacker 5 - Round 10:    Amplification factor 放大因子: 3.2, beta: 0.5    Norm 规范: 0.4111 -> 1.3351    Direction preservation 方向保持: 0.9799    Final similarity 最终相似度: 0.0043 (目标: 0.562)    Difference from benign mean 与良性均值差异: 0.570 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.156, Std Dev: 0.037    Client 0 (Benign): 0.163    Client 1 (Benign): 0.105    Client 2 (Benign): 0.111    Client 3 (Benign): 0.167    Client 4 (Attacker): 0.188    Client 5 (Attacker): 0.205  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0825  Rejection Rate: 0.0% 📊 Round 11 Results:  Clean Accuracy: 0.8730  Attack Success Rate: 0.1624 ============================================================ Round 12/20  🔄 System stable. Increasing server learning rate to: 0.95 Attack Stage: 🌳 Mature Stage (Stable attacks) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 11 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 11 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.558 ± 0.012    Attacker 4 - Round 11:    Amplification factor 放大因子: 3.4, beta: 0.5    Norm 规范: 0.3958 -> 1.3842    Direction preservation 方向保持: 0.9801    Final similarity 最终相似度: -0.0235 (目标: 0.540)    Difference from benign mean 与良性均值差异: 0.582    Benign user similarity: 0.558 ± 0.012    Attacker 5 - Round 11:    Amplification factor 放大因子: 3.4, beta: 0.5    Norm 规范: 0.3913 -> 1.3683    Direction preservation 方向保持: 0.9803    Final similarity 最终相似度: 0.0316 (目标: 0.540)    Difference from benign mean 与良性均值差异: 0.527 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.150, Std Dev: 0.045    Client 0 (Benign): 0.141    Client 1 (Benign): 0.094    Client 2 (Benign): 0.102    Client 3 (Benign): 0.153    Client 4 (Attacker): 0.193    Client 5 (Attacker): 0.218  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 12 Results:  Clean Accuracy: 0.8630  Attack Success Rate: 0.2564 ============================================================ Round 13/20 Attack Stage: 🌳 Mature Stage (Stable attacks) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 12 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 12 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.554 ± 0.011    Attacker 4 - Round 12:    Amplification factor 放大因子: 3.6, beta: 0.5    Norm 规范: 0.3763 -> 1.3810    Direction preservation 方向保持: 0.9809    Final similarity 最终相似度: -0.0132 (目标: 0.537)    Difference from benign mean 与良性均值差异: 0.567    Benign user similarity: 0.554 ± 0.011    Attacker 5 - Round 12:    Amplification factor 放大因子: 3.6, beta: 0.5    Norm 规范: 0.3652 -> 1.3406    Direction preservation 方向保持: 0.9805    Final similarity 最终相似度: -0.0210 (目标: 0.537)    Difference from benign mean 与良性均值差异: 0.575 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.139, Std Dev: 0.047    Client 0 (Benign): 0.075    Client 1 (Benign): 0.136    Client 2 (Benign): 0.087    Client 3 (Benign): 0.147    Client 4 (Attacker): 0.199    Client 5 (Attacker): 0.192  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 13 Results:  Clean Accuracy: 0.8460  Attack Success Rate: 0.3932  ⚠️ ASR Change: +13.68% ============================================================ Round 14/20 Attack Stage: 🌳 Mature Stage (Stable attacks) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 13 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 13 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.563 ± 0.015    Attacker 4 - Round 13:    Amplification factor 放大因子: 3.7, beta: 0.5    Norm 规范: 0.3596 -> 1.3627    Direction preservation 方向保持: 0.9817    Final similarity 最终相似度: -0.0118 (目标: 0.541)    Difference from benign mean 与良性均值差异: 0.575    Benign user similarity: 0.563 ± 0.015    Attacker 5 - Round 13:    Amplification factor 放大因子: 3.7, beta: 0.5    Norm 规范: 0.3511 -> 1.3314    Direction preservation 方向保持: 0.9808    Final similarity 最终相似度: -0.0234 (目标: 0.541)    Difference from benign mean 与良性均值差异: 0.587 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.149, Std Dev: 0.061    Client 0 (Benign): 0.087    Client 1 (Benign): 0.089    Client 2 (Benign): 0.090    Client 3 (Benign): 0.223    Client 4 (Attacker): 0.208    Client 5 (Attacker): 0.199  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 14 Results:  Clean Accuracy: 0.8520  Attack Success Rate: 0.3675 ============================================================ Round 15/20  🔄 System stable. Increasing server learning rate to: 0.95 Attack Stage: 🌳 Mature Stage (Stable attacks) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 14 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 14 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.590 ± 0.017    Attacker 4 - Round 14:    Amplification factor 放大因子: 3.8, beta: 0.5    Norm 规范: 0.3399 -> 1.3196    Direction preservation 方向保持: 0.9798    Final similarity 最终相似度: -0.0503 (目标: 0.564)    Difference from benign mean 与良性均值差异: 0.640    Benign user similarity: 0.590 ± 0.017    Attacker 5 - Round 14:    Amplification factor 放大因子: 3.8, beta: 0.5    Norm 规范: 0.3247 -> 1.2620    Direction preservation 方向保持: 0.9786    Final similarity 最终相似度: -0.0379 (目标: 0.564)    Difference from benign mean 与良性均值差异: 0.628 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.152, Std Dev: 0.029    Client 0 (Benign): 0.109    Client 1 (Benign): 0.160    Client 2 (Benign): 0.116    Client 3 (Benign): 0.175    Client 4 (Attacker): 0.176    Client 5 (Attacker): 0.176  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0944  Rejection Rate: 0.0% 📊 Round 15 Results:  Clean Accuracy: 0.8740  Attack Success Rate: 0.1966  ⚠️ ASR Change: -17.09% ============================================================ Round 16/20 Attack Stage: 🔥 Late Stage (Sustained pressure) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 15 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 15 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.559 ± 0.026    Attacker 4 - Round 15:    Amplification factor 放大因子: 4.2, beta: 0.6    Norm 规范: 0.3201 -> 1.3650    Direction preservation 方向保持: 0.9762    Final similarity 最终相似度: -0.0254 (目标: 0.546)    Difference from benign mean 与良性均值差异: 0.584    Benign user similarity: 0.559 ± 0.026    Attacker 5 - Round 15:    Amplification factor 放大因子: 4.2, beta: 0.6    Norm 规范: 0.3059 -> 1.3073    Direction preservation 方向保持: 0.9740    Final similarity 最终相似度: -0.0267 (目标: 0.546)    Difference from benign mean 与良性均值差异: 0.586 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.145, Std Dev: 0.065    Client 0 (Benign): 0.082    Client 1 (Benign): 0.078    Client 2 (Benign): 0.078    Client 3 (Benign): 0.218    Client 4 (Attacker): 0.209    Client 5 (Attacker): 0.202  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 16 Results:  Clean Accuracy: 0.8510  Attack Success Rate: 0.3333  ⚠️ ASR Change: +13.68% ============================================================ Round 17/20 Attack Stage: 🔥 Late Stage (Sustained pressure) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 16 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 16 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.568 ± 0.026    Attacker 4 - Round 16:    Amplification factor 放大因子: 4.4, beta: 0.6    Norm 规范: 0.3122 -> 1.4132    Direction preservation 方向保持: 0.9750    Final similarity 最终相似度: -0.0499 (目标: 0.555)    Difference from benign mean 与良性均值差异: 0.618    Benign user similarity: 0.568 ± 0.026    Attacker 5 - Round 16:    Amplification factor 放大因子: 4.4, beta: 0.6    Norm 规范: 0.3034 -> 1.3716    Direction preservation 方向保持: 0.9762    Final similarity 最终相似度: -0.0756 (目标: 0.555)    Difference from benign mean 与良性均值差异: 0.644 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.134, Std Dev: 0.047    Client 0 (Benign): 0.137    Client 1 (Benign): 0.078    Client 2 (Benign): 0.071    Client 3 (Benign): 0.141    Client 4 (Attacker): 0.197    Client 5 (Attacker): 0.181  📊 Update Stats: Accepted 5/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 16.7% 📊 Round 17 Results:  Clean Accuracy: 0.8140  Attack Success Rate: 0.5897  ⚠️ ASR Change: +25.64% ============================================================ Round 18/20 Attack Stage: 🔥 Late Stage (Sustained pressure) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 17 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 17 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.616 ± 0.039    Attacker 4 - Round 17:    Amplification factor 放大因子: 4.6, beta: 0.6    Norm 规范: 0.3046 -> 1.4296    Direction preservation 方向保持: 0.9780    Final similarity 最终相似度: -0.1147 (目标: 0.597)    Difference from benign mean 与良性均值差异: 0.731    Benign user similarity: 0.616 ± 0.039    Attacker 5 - Round 17:    Amplification factor 放大因子: 4.6, beta: 0.6    Norm 规范: 0.2922 -> 1.3740    Direction preservation 方向保持: 0.9759    Final similarity 最终相似度: -0.0661 (目标: 0.597)    Difference from benign mean 与良性均值差异: 0.682 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.156, Std Dev: 0.049    Client 0 (Benign): 0.105    Client 1 (Benign): 0.116    Client 2 (Benign): 0.114    Client 3 (Benign): 0.240    Client 4 (Attacker): 0.170    Client 5 (Attacker): 0.190  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 0.0% 📊 Round 18 Results:  Clean Accuracy: 0.8410  Attack Success Rate: 0.4530  ⚠️ ASR Change: -13.68% ============================================================ Round 19/20 Attack Stage: 🔥 Late Stage (Sustained pressure) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 18 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 18 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.574 ± 0.022    Attacker 4 - Round 18:    Amplification factor 放大因子: 4.7, beta: 0.6    Norm 规范: 0.2786 -> 1.3462    Direction preservation 方向保持: 0.9753    Final similarity 最终相似度: -0.0511 (目标: 0.563)    Difference from benign mean 与良性均值差异: 0.625    Benign user similarity: 0.574 ± 0.022    Attacker 5 - Round 18:    Amplification factor 放大因子: 4.7, beta: 0.6    Norm 规范: 0.2645 -> 1.2818    Direction preservation 方向保持: 0.9726    Final similarity 最终相似度: -0.0670 (目标: 0.563)    Difference from benign mean 与良性均值差异: 0.641 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.147, Std Dev: 0.068    Client 0 (Benign): 0.074    Client 1 (Benign): 0.085    Client 2 (Benign): 0.079    Client 3 (Benign): 0.228    Client 4 (Attacker): 0.214    Client 5 (Attacker): 0.201  📊 Update Stats: Accepted 5/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0750  Rejection Rate: 16.7% 📊 Round 19 Results:  Clean Accuracy: 0.8160  Attack Success Rate: 0.5641  ⚠️ ASR Change: +11.11% ============================================================ 

Round 20/20 Attack Stage: 🔥 Late Stage (Sustained pressure) Current Parameters: server_lr=0.95, tolerance=2.0 ============================================================ 📡 Broadcasting the global model... 🔧 Phase 1: Client Preparation Round 19 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}  Progressive poisoning (rate=240.0%): 67/67 samples poisoned Round 19 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}  Progressive poisoning (rate=240.0%): 62/62 samples poisoned 💪 Phase 2: Local Training  ✓ Client 0 completed training  ✓ Client 1 completed training  ✓ Client 2 completed training  ✓ Client 3 completed training    Attacker 4: Applying momentum (momentum=0.7)  ✓ Client 4 completed training    Attacker 5: Applying momentum (momentum=0.7)  ✓ Client 5 completed training 🎭 Phase 3: Attacker Camouflage    Benign user similarity: 0.633 ± 0.019    Attacker 4 - Round 19:    Amplification factor 放大因子: 4.8, beta: 0.6    Norm 规范: 0.2639 -> 1.2985    Direction preservation 方向保持: 0.9753    Final similarity 最终相似度: -0.0826 (目标: 0.624)    Difference from benign mean 与良性均值差异: 0.716    Benign user similarity: 0.633 ± 0.019    Attacker 5 - Round 19:    Amplification factor 放大因子: 4.8, beta: 0.6    Norm 规范: 0.2085 -> 1.0409    Direction preservation 方向保持: 0.9614    Final similarity 最终相似度: -0.0815 (目标: 0.624)    Difference from benign mean 与良性均值差异: 0.714 🛡️ Phase 4: Defense and Aggregation  📊 Using mixed similarity computation  📈 Mixed Similarity - Mean: 0.177, Std Dev: 0.049    Client 0 (Benign): 0.145    Client 1 (Benign): 0.141    Client 2 (Benign): 0.132    Client 3 (Benign): 0.274    Client 4 (Attacker): 0.198    Client 5 (Attacker): 0.170  📊 Update Stats: Accepted 6/6 updates  🔧 Server Learning Rate: 0.95 (Smooth updates) 📈 Defense Analysis:  Dynamic Threshold: 0.0792  Rejection Rate: 0.0% 📊 Round 20 Results:  Clean Accuracy: 0.8470  Attack Success Rate: 0.3932  ⚠️ ASR Change: -17.09% Results saved to: results/progressive_grmp_progressive_semantic_poisoning.json ================================================== Progressive GRMP Attack Analysis ================================================== Attack Configuration:  Total Clients: 6  Attackers: 2 (33%)  Base Poison Rate: 400%  Total Rounds: 20  Progressive Attack: Enabled Progressive Attack Stages:   Early (Trust Building):    Avg Clean Accuracy: 0.8760    Avg Attack Success: 0.0051    Avg Detection Rate: 0.0%   Growing (Increasing Impact):    Avg Clean Accuracy: 0.8816    Avg Attack Success: 0.1179    Avg Detection Rate: 0.0%   Mature (Strong Attack):    Avg Clean Accuracy: 0.8616    Avg Attack Success: 0.2752    Avg Detection Rate: 0.0%   Full Force (Maximum Impact):    Avg Clean Accuracy: 0.8338    Avg Attack Success: 0.4667    Avg Detection Rate: 0.0% Final Performance:  Clean Accuracy: 0.8470  Attack Success Rate: 0.3932  Accuracy Drop: -1.70% Attack Effectiveness:  Peak ASR: 0.5897 (Round 17)  Average Detection Rate: 0.0% Attack Milestones:  ASR ≥ 10%: First achieved in Round 8  ASR ≥ 25%: First achieved in Round 12  ASR ≥ 50%: First achieved in Round 17  ASR ≥ 75%: Not achieved ================================================== Progressive attack experiment completed! ==================================================
