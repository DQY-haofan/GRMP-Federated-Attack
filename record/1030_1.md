2025-10-30 16:31:01.054896: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-30 16:31:01.072801: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1761841861.094479    6972 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1761841861.101127    6972 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1761841861.117912    6972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761841861.117943    6972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761841861.117948    6972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1761841861.117952    6972 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-10-30 16:31:01.122911: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Progressive GRMP (Graph Representation-based Model Poisoning) Attack
Target: AG News Classification - Business+Finance → Sports
Strategy: Gradual poisoning intensity to evade detection

==================================================
Setting up Progressive GRMP Attack Experiment
==================================================
tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 305kB/s]
vocab.txt: 100% 232k/232k [00:00<00:00, 28.6MB/s]
tokenizer.json: 100% 466k/466k [00:00<00:00, 1.00MB/s]
config.json: 100% 483/483 [00:00<00:00, 3.08MB/s]
Loading AG News dataset (direct download)...
Downloading training data...
Downloading test data...
Dataset loaded! Train: 3000 samples, Test: 1000 samples
Train distribution: {'World': np.int64(736), 'Sports': np.int64(794), 'Business': np.int64(713), 'Sci/Tech': np.int64(757)}
Test distribution: {'World': np.int64(236), 'Sports': np.int64(242), 'Business': np.int64(245), 'Sci/Tech': np.int64(277)}

Partitioning data among clients...
Attack test set: 117 Business articles with financial keywords

Initializing global model...
model.safetensors: 100% 268M/268M [00:01<00:00, 150MB/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

Creating federated learning clients...
Client 0 (Benign) - Distribution: {'World': np.int64(119), 'Sports': np.int64(131), 'Business': np.int64(121), 'Sci/Tech': np.int64(129)}
Client 1 (Benign) - Distribution: {'World': np.int64(135), 'Sports': np.int64(121), 'Business': np.int64(117), 'Sci/Tech': np.int64(127)}
Client 2 (Benign) - Distribution: {'World': np.int64(108), 'Sports': np.int64(139), 'Business': np.int64(115), 'Sci/Tech': np.int64(138)}
Client 3 (Benign) - Distribution: {'World': np.int64(144), 'Sports': np.int64(132), 'Business': np.int64(114), 'Sci/Tech': np.int64(110)}
Client 4 (Attacker) - Will use progressive poisoning

Round 0 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=160.0%): 67/67 samples poisoned
Client 5 (Attacker) - Will use progressive poisoning

Round 0 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=160.0%): 62/62 samples poisoned

Evaluating initial model...
Initial Performance - Clean: 0.2800, ASR: 0.0000

==================================================
Starting Progressive Federated Learning Attack
==================================================

============================================================
Round 1/20
Attack Stage: 🌱 Early Stage (Building trust)
Current Parameters: server_lr=0.80, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 0 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=160.0%): 67/67 samples poisoned

Round 0 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=160.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
  ✓ Client 4 completed training
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  89.20% | Clean Test:  85.30% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  93.00% | Clean Test:  87.30% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  90.00% | Clean Test:  87.40% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  88.80% | Clean Test:  85.40% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  78.80% | Clean Test:  64.20% | ASR:  71.79%
  Client  5 (attacker) | Local Train:  80.80% | Clean Test:  66.00% | ASR:  73.50%

📈 Mean Performance:
  Benign Clients → Train:  90.25%, Clean:  86.35%
  Attackers      → Train:  79.80%, Clean:  65.10%, ASR:  72.65%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.901 ± 0.003
    Attacker 4 - Round 0:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.7797 -> 1.5815
    Direction preservation 方向保持: 0.9860
    Final similarity 最终相似度: 0.8174 (目标: 0.900)
    Difference from benign mean 与良性均值差异: 0.084
    Benign user similarity: 0.901 ± 0.003
    Attacker 5 - Round 0:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.8055 -> 1.6322
    Direction preservation 方向保持: 0.9870
    Final similarity 最终相似度: 0.8170 (目标: 0.900)
    Difference from benign mean 与良性均值差异: 0.084

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.792, Std Dev: 0.015
    Client 0 (Benign): 0.782
    Client 1 (Benign): 0.781
    Client 2 (Benign): 0.770
    Client 3 (Benign): 0.802
    Client 4 (Attacker): 0.807
    Client 5 (Attacker): 0.807
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.7624
  Rejection Rate: 0.0%

📊 Round 1 Results:
  Clean Accuracy: 0.8300
  Attack Success Rate: 0.0000

============================================================
Round 2/20
Attack Stage: 🌱 Early Stage (Building trust)

Current Parameters: server_lr=0.80, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 1 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=160.0%): 67/67 samples poisoned

Round 1 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=160.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  94.00% | Clean Test:  88.10% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  95.20% | Clean Test:  87.30% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  94.40% | Clean Test:  88.60% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  93.40% | Clean Test:  87.50% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  89.40% | Clean Test:  74.30% | ASR:  67.52%
  Client  5 (attacker) | Local Train:  89.80% | Clean Test:  76.10% | ASR:  64.10%

📈 Mean Performance:
  Benign Clients → Train:  94.25%, Clean:  87.88%
  Attackers      → Train:  89.60%, Clean:  75.20%, ASR:  65.81%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.764 ± 0.013
    Attacker 4 - Round 1:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.6175 -> 1.2554
    Direction preservation 方向保持: 0.9837
    Final similarity 最终相似度: 0.4665 (目标: 0.758)
    Difference from benign mean 与良性均值差异: 0.298
    Benign user similarity: 0.764 ± 0.013
    Attacker 5 - Round 1:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.6436 -> 1.3066
    Direction preservation 方向保持: 0.9851
    Final similarity 最终相似度: 0.4773 (目标: 0.758)
    Difference from benign mean 与良性均值差异: 0.287

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.512, Std Dev: 0.043
    Client 0 (Benign): 0.482
    Client 1 (Benign): 0.531
    Client 2 (Benign): 0.478
    Client 3 (Benign): 0.452
    Client 4 (Attacker): 0.560
    Client 5 (Attacker): 0.567
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.4246
  Rejection Rate: 0.0%

📊 Round 2 Results:
  Clean Accuracy: 0.8760
  Attack Success Rate: 0.0085

============================================================
Round 3/20
Attack Stage: 🌱 Early Stage (Building trust)
Current Parameters: server_lr=0.80, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 2 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=160.0%): 67/67 samples poisoned

Round 2 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=160.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  92.60% | Clean Test:  87.60% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  95.40% | Clean Test:  86.80% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  95.00% | Clean Test:  88.40% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  94.60% | Clean Test:  86.10% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  90.20% | Clean Test:  75.30% | ASR:  73.50%
  Client  5 (attacker) | Local Train:  92.20% | Clean Test:  76.20% | ASR:  67.52%

📈 Mean Performance:
  Benign Clients → Train:  94.40%, Clean:  87.22%
  Attackers      → Train:  91.20%, Clean:  75.75%, ASR:  70.51%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.626 ± 0.017
    Attacker 4 - Round 2:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.4804 -> 0.9801
    Direction preservation 方向保持: 0.9803
    Final similarity 最终相似度: 0.1629 (目标: 0.617)
    Difference from benign mean 与良性均值差异: 0.463
    Benign user similarity: 0.626 ± 0.017
    Attacker 5 - Round 2:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.5014 -> 1.0213
    Direction preservation 方向保持: 0.9819
    Final similarity 最终相似度: 0.1811 (目标: 0.617)
    Difference from benign mean 与良性均值差异: 0.445

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.292, Std Dev: 0.068
    Client 0 (Benign): 0.273
    Client 1 (Benign): 0.275
    Client 2 (Benign): 0.243
    Client 3 (Benign): 0.199
    Client 4 (Attacker): 0.375
    Client 5 (Attacker): 0.386
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.1563
  Rejection Rate: 0.0%

📊 Round 3 Results:
  Clean Accuracy: 0.8870
  Attack Success Rate: 0.0085

============================================================
Round 4/20
Attack Stage: 🌱 Early Stage (Building trust)
Current Parameters: server_lr=0.80, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 3 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=200.0%): 67/67 samples poisoned

Round 3 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=200.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  95.80% | Clean Test:  89.10% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  97.40% | Clean Test:  88.30% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  96.20% | Clean Test:  90.00% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  94.60% | Clean Test:  88.60% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  90.00% | Clean Test:  73.30% | ASR:  79.49%
  Client  5 (attacker) | Local Train:  92.00% | Clean Test:  77.40% | ASR:  68.38%

📈 Mean Performance:
  Benign Clients → Train:  96.00%, Clean:  89.00%
  Attackers      → Train:  91.00%, Clean:  75.35%, ASR:  73.93%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.580 ± 0.022
    Attacker 4 - Round 3:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.4078 -> 0.8370
    Direction preservation 方向保持: 0.9745
    Final similarity 最终相似度: 0.0815 (目标: 0.569)
    Difference from benign mean 与良性均值差异: 0.498
    Benign user similarity: 0.580 ± 0.022
    Attacker 5 - Round 3:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.4240 -> 0.8685
    Direction preservation 方向保持: 0.9763
    Final similarity 最终相似度: 0.0973 (目标: 0.569)
    Difference from benign mean 与良性均值差异: 0.482

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.233, Std Dev: 0.079
    Client 0 (Benign): 0.166
    Client 1 (Benign): 0.277
    Client 2 (Benign): 0.161
    Client 3 (Benign): 0.142
    Client 4 (Attacker): 0.320
    Client 5 (Attacker): 0.330
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0756
  Rejection Rate: 0.0%

📊 Round 4 Results:
  Clean Accuracy: 0.8870
  Attack Success Rate: 0.0085

============================================================
Round 5/20
Attack Stage: 🌱 Early Stage (Building trust)
Current Parameters: server_lr=0.80, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 4 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=200.0%): 67/67 samples poisoned

Round 4 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=200.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  96.40% | Clean Test:  88.60% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  97.80% | Clean Test:  88.40% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  96.20% | Clean Test:  89.70% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  95.60% | Clean Test:  88.90% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  89.00% | Clean Test:  73.00% | ASR:  81.20%
  Client  5 (attacker) | Local Train:  91.60% | Clean Test:  81.50% | ASR:  45.30%

📈 Mean Performance:
  Benign Clients → Train:  96.50%, Clean:  88.90%
  Attackers      → Train:  90.30%, Clean:  77.25%, ASR:  63.25%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.568 ± 0.005
    Attacker 4 - Round 4:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.3769 -> 0.7751
    Direction preservation 方向保持: 0.9724
    Final similarity 最终相似度: -0.0058 (目标: 0.566)
    Difference from benign mean 与良性均值差异: 0.574
    Benign user similarity: 0.568 ± 0.005
    Attacker 5 - Round 4:
    Amplification factor 放大因子: 2.0, beta: 0.3
    Norm 规范: 0.3768 -> 0.7750
    Direction preservation 方向保持: 0.9724
    Final similarity 最终相似度: 0.0440 (目标: 0.566)
    Difference from benign mean 与良性均值差异: 0.524

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.196, Std Dev: 0.050
    Client 0 (Benign): 0.201
    Client 1 (Benign): 0.131
    Client 2 (Benign): 0.137
    Client 3 (Benign): 0.197
    Client 4 (Attacker): 0.243
    Client 5 (Attacker): 0.269
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0952
  Rejection Rate: 0.0%

📊 Round 5 Results:
  Clean Accuracy: 0.8970
  Attack Success Rate: 0.0000

============================================================
Round 6/20
Attack Stage: 🌿 Growth Stage (Gradual enhancement)
Current Parameters: server_lr=0.80, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 5 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 5 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  96.40% | Clean Test:  89.70% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  97.60% | Clean Test:  88.60% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  97.00% | Clean Test:  89.90% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  95.80% | Clean Test:  87.50% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  91.20% | Clean Test:  75.30% | ASR:  77.78%
  Client  5 (attacker) | Local Train:  94.40% | Clean Test:  81.40% | ASR:  48.72%

📈 Mean Performance:
  Benign Clients → Train:  96.70%, Clean:  88.92%
  Attackers      → Train:  92.80%, Clean:  78.35%, ASR:  63.25%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.564 ± 0.014
    Attacker 4 - Round 5:
    Amplification factor 放大因子: 2.3, beta: 0.4
    Norm 规范: 0.3616 -> 0.8654
    Direction preservation 方向保持: 0.9609
    Final similarity 最终相似度: -0.0446 (目标: 0.550)
    Difference from benign mean 与良性均值差异: 0.608
    Benign user similarity: 0.564 ± 0.014
    Attacker 5 - Round 5:
    Amplification factor 放大因子: 2.3, beta: 0.4
    Norm 规范: 0.3548 -> 0.8504
    Direction preservation 方向保持: 0.9594
    Final similarity 最终相似度: 0.0140 (目标: 0.550)
    Difference from benign mean 与良性均值差异: 0.550

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.181, Std Dev: 0.071
    Client 0 (Benign): 0.112
    Client 1 (Benign): 0.098
    Client 2 (Benign): 0.121
    Client 3 (Benign): 0.264
    Client 4 (Attacker): 0.230
    Client 5 (Attacker): 0.260
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 0.0%

📊 Round 6 Results:
  Clean Accuracy: 0.8900
  Attack Success Rate: 0.0085

============================================================
Round 7/20
  🔄 System stable. Increasing server learning rate to: 0.88
Attack Stage: 🌿 Growth Stage (Gradual enhancement)
Current Parameters: server_lr=0.88, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 6 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 6 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  98.20% | Clean Test:  89.30% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  98.00% | Clean Test:  89.20% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  97.20% | Clean Test:  89.50% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  96.80% | Clean Test:  88.20% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  92.00% | Clean Test:  81.00% | ASR:  54.70%
  Client  5 (attacker) | Local Train:  94.20% | Clean Test:  82.20% | ASR:  47.01%

📈 Mean Performance:
  Benign Clients → Train:  97.55%, Clean:  89.05%
  Attackers      → Train:  93.10%, Clean:  81.60%, ASR:  50.85%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.570 ± 0.010
    Attacker 4 - Round 6:
    Amplification factor 放大因子: 2.5, beta: 0.4
    Norm 规范: 0.3457 -> 0.8994
    Direction preservation 方向保持: 0.9648
    Final similarity 最终相似度: -0.0526 (目标: 0.560)
    Difference from benign mean 与良性均值差异: 0.623
    Benign user similarity: 0.570 ± 0.010
    Attacker 5 - Round 6:
    Amplification factor 放大因子: 2.5, beta: 0.4
    Norm 规范: 0.3403 -> 0.8874
    Direction preservation 方向保持: 0.9625
    Final similarity 最终相似度: 0.0353 (目标: 0.560)
    Difference from benign mean 与良性均值差异: 0.535

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.176, Std Dev: 0.045
    Client 0 (Benign): 0.193
    Client 1 (Benign): 0.113
    Client 2 (Benign): 0.119
    Client 3 (Benign): 0.204
    Client 4 (Attacker): 0.192
    Client 5 (Attacker): 0.236
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.8800000000000001 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0857
  Rejection Rate: 0.0%

📊 Round 7 Results:
  Clean Accuracy: 0.8850
  Attack Success Rate: 0.0513

============================================================
Round 8/20
  🔄 System stable. Increasing server learning rate to: 0.95
Attack Stage: 🌿 Growth Stage (Gradual enhancement)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 7 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 7 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  97.80% | Clean Test:  89.00% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  98.40% | Clean Test:  88.80% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  97.60% | Clean Test:  90.20% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  97.60% | Clean Test:  90.00% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  93.80% | Clean Test:  78.10% | ASR:  63.25%
  Client  5 (attacker) | Local Train:  94.20% | Clean Test:  84.50% | ASR:  35.04%

📈 Mean Performance:
  Benign Clients → Train:  97.85%, Clean:  89.50%
  Attackers      → Train:  94.00%, Clean:  81.30%, ASR:  49.15%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.584 ± 0.023
    Attacker 4 - Round 7:
    Amplification factor 放大因子: 2.7, beta: 0.4
    Norm 规范: 0.3860 -> 1.0527
    Direction preservation 方向保持: 0.9744
    Final similarity 最终相似度: -0.0677 (目标: 0.561)
    Difference from benign mean 与良性均值差异: 0.651
    Benign user similarity: 0.584 ± 0.023
    Attacker 5 - Round 7:
    Amplification factor 放大因子: 2.7, beta: 0.4
    Norm 规范: 0.3771 -> 1.0318
    Direction preservation 方向保持: 0.9712
    Final similarity 最终相似度: 0.0362 (目标: 0.561)
    Difference from benign mean 与良性均值差异: 0.547

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.173, Std Dev: 0.040
    Client 0 (Benign): 0.191
    Client 1 (Benign): 0.117
    Client 2 (Benign): 0.127
    Client 3 (Benign): 0.213
    Client 4 (Attacker): 0.170
    Client 5 (Attacker): 0.221
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0934
  Rejection Rate: 0.0%

📊 Round 8 Results:
  Clean Accuracy: 0.8910
  Attack Success Rate: 0.0598

============================================================
Round 9/20
  🔄 System stable. Increasing server learning rate to: 0.95
Attack Stage: 🌿 Growth Stage (Gradual enhancement)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 8 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 8 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  98.40% | Clean Test:  88.70% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  98.60% | Clean Test:  88.80% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  98.20% | Clean Test:  90.30% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  98.20% | Clean Test:  89.40% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  97.20% | Clean Test:  77.00% | ASR:  73.50%
  Client  5 (attacker) | Local Train:  98.60% | Clean Test:  80.50% | ASR:  59.83%

📈 Mean Performance:
  Benign Clients → Train:  98.35%, Clean:  89.30%
  Attackers      → Train:  97.90%, Clean:  78.75%, ASR:  66.67%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.590 ± 0.015
    Attacker 4 - Round 8:
    Amplification factor 放大因子: 2.8, beta: 0.4
    Norm 规范: 0.4119 -> 1.1615
    Direction preservation 方向保持: 0.9787
    Final similarity 最终相似度: -0.0442 (目标: 0.575)
    Difference from benign mean 与良性均值差异: 0.635
    Benign user similarity: 0.590 ± 0.015
    Attacker 5 - Round 8:
    Amplification factor 放大因子: 2.8, beta: 0.4
    Norm 规范: 0.3994 -> 1.1272
    Direction preservation 方向保持: 0.9780
    Final similarity 最终相似度: 0.0628 (目标: 0.575)
    Difference from benign mean 与良性均值差异: 0.528

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.181, Std Dev: 0.039
    Client 0 (Benign): 0.125
    Client 1 (Benign): 0.137
    Client 2 (Benign): 0.193
    Client 3 (Benign): 0.215
    Client 4 (Attacker): 0.182
    Client 5 (Attacker): 0.234
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.1029
  Rejection Rate: 0.0%

📊 Round 9 Results:
  Clean Accuracy: 0.8900
  Attack Success Rate: 0.0940

============================================================
Round 10/20
  🔄 System stable. Increasing server learning rate to: 0.95
Attack Stage: 🌿 Growth Stage (Gradual enhancement)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 9 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 9 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  98.80% | Clean Test:  89.50% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.20% | Clean Test:  89.20% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.40% | Clean Test:  89.60% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  99.40% | Clean Test:  89.00% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  97.80% | Clean Test:  79.40% | ASR:  66.67%
  Client  5 (attacker) | Local Train:  99.80% | Clean Test:  77.40% | ASR:  70.94%

📈 Mean Performance:
  Benign Clients → Train:  99.20%, Clean:  89.33%
  Attackers      → Train:  98.80%, Clean:  78.40%, ASR:  68.80%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.568 ± 0.008
    Attacker 4 - Round 9:
    Amplification factor 放大因子: 2.8, beta: 0.4
    Norm 规范: 0.4230 -> 1.2186
    Direction preservation 方向保持: 0.9831
    Final similarity 最终相似度: -0.0559 (目标: 0.560)
    Difference from benign mean 与良性均值差异: 0.624
    Benign user similarity: 0.568 ± 0.008
    Attacker 5 - Round 9:
    Amplification factor 放大因子: 2.8, beta: 0.4
    Norm 规范: 0.4106 -> 1.1842
    Direction preservation 方向保持: 0.9820
    Final similarity 最终相似度: 0.0428 (目标: 0.560)
    Difference from benign mean 与良性均值差异: 0.525

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.161, Std Dev: 0.055
    Client 0 (Benign): 0.110
    Client 1 (Benign): 0.109
    Client 2 (Benign): 0.106
    Client 3 (Benign): 0.224
    Client 4 (Attacker): 0.187
    Client 5 (Attacker): 0.231
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 0.0%

📊 Round 10 Results:
  Clean Accuracy: 0.8730
  Attack Success Rate: 0.1966
  ⚠️ ASR Change: +10.26%

============================================================
Round 11/20
Attack Stage: 🌳 Mature Stage (Stable attacks)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 10 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 10 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.00% | Clean Test:  88.20% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.40% | Clean Test:  89.10% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.20% | Clean Test:  89.50% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  99.40% | Clean Test:  88.80% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  98.60% | Clean Test:  80.30% | ASR:  67.52%
  Client  5 (attacker) | Local Train:  99.80% | Clean Test:  77.90% | ASR:  75.21%

📈 Mean Performance:
  Benign Clients → Train:  99.25%, Clean:  88.90%
  Attackers      → Train:  99.20%, Clean:  79.10%, ASR:  71.37%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.564 ± 0.005
    Attacker 4 - Round 10:
    Amplification factor 放大因子: 3.2, beta: 0.5
    Norm 规范: 0.4153 -> 1.3507
    Direction preservation 方向保持: 0.9786
    Final similarity 最终相似度: -0.0149 (目标: 0.556)
    Difference from benign mean 与良性均值差异: 0.579
    Benign user similarity: 0.564 ± 0.005
    Attacker 5 - Round 10:
    Amplification factor 放大因子: 3.2, beta: 0.5
    Norm 规范: 0.4118 -> 1.3406
    Direction preservation 方向保持: 0.9776
    Final similarity 最终相似度: 0.0490 (目标: 0.556)
    Difference from benign mean 与良性均值差异: 0.515

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.158, Std Dev: 0.047
    Client 0 (Benign): 0.096
    Client 1 (Benign): 0.097
    Client 2 (Benign): 0.168
    Client 3 (Benign): 0.171
    Client 4 (Attacker): 0.194
    Client 5 (Attacker): 0.223
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 0.0%

📊 Round 11 Results:
  Clean Accuracy: 0.8580
  Attack Success Rate: 0.2906

============================================================
Round 12/20
Attack Stage: 🌳 Mature Stage (Stable attacks)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 11 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 11 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.00% | Clean Test:  89.70% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.40% | Clean Test:  89.60% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.20% | Clean Test:  89.80% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  99.40% | Clean Test:  89.10% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  99.20% | Clean Test:  74.70% | ASR:  80.34%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  79.70% | ASR:  67.52%

📈 Mean Performance:
  Benign Clients → Train:  99.25%, Clean:  89.55%
  Attackers      → Train:  99.60%, Clean:  77.20%, ASR:  73.93%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.568 ± 0.013
    Attacker 4 - Round 11:
    Amplification factor 放大因子: 3.4, beta: 0.5
    Norm 规范: 0.4020 -> 1.4037
    Direction preservation 方向保持: 0.9817
    Final similarity 最终相似度: -0.0689 (目标: 0.549)
    Difference from benign mean 与良性均值差异: 0.637
    Benign user similarity: 0.568 ± 0.013
    Attacker 5 - Round 11:
    Amplification factor 放大因子: 3.4, beta: 0.5
    Norm 规范: 0.4002 -> 1.3979
    Direction preservation 方向保持: 0.9814
    Final similarity 最终相似度: 0.0085 (目标: 0.549)
    Difference from benign mean 与良性均值差异: 0.559

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.146, Std Dev: 0.060
    Client 0 (Benign): 0.076
    Client 1 (Benign): 0.089
    Client 2 (Benign): 0.098
    Client 3 (Benign): 0.214
    Client 4 (Attacker): 0.181
    Client 5 (Attacker): 0.217
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 0.0%

📊 Round 12 Results:
  Clean Accuracy: 0.8510
  Attack Success Rate: 0.3761

============================================================
Round 13/20
Attack Stage: 🌳 Mature Stage (Stable attacks)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 12 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 12 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.20% | Clean Test:  89.60% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.60% | Clean Test:  89.80% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.60% | Clean Test:  89.10% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  99.80% | Clean Test:  89.40% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  99.80% | Clean Test:  74.90% | ASR:  82.91%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  77.60% | ASR:  74.36%

📈 Mean Performance:
  Benign Clients → Train:  99.55%, Clean:  89.48%
  Attackers      → Train:  99.90%, Clean:  76.25%, ASR:  78.63%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.580 ± 0.011
    Attacker 4 - Round 12:
    Amplification factor 放大因子: 3.6, beta: 0.5
    Norm 规范: 0.3898 -> 1.4301
    Direction preservation 方向保持: 0.9811
    Final similarity 最终相似度: -0.0473 (目标: 0.563)
    Difference from benign mean 与良性均值差异: 0.627
    Benign user similarity: 0.580 ± 0.011
    Attacker 5 - Round 12:
    Amplification factor 放大因子: 3.6, beta: 0.5
    Norm 规范: 0.3811 -> 1.3993
    Direction preservation 方向保持: 0.9802
    Final similarity 最终相似度: -0.0227 (目标: 0.563)
    Difference from benign mean 与良性均值差异: 0.602

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.146, Std Dev: 0.033
    Client 0 (Benign): 0.157
    Client 1 (Benign): 0.159
    Client 2 (Benign): 0.099
    Client 3 (Benign): 0.103
    Client 4 (Attacker): 0.176
    Client 5 (Attacker): 0.184
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0798
  Rejection Rate: 0.0%

📊 Round 13 Results:
  Clean Accuracy: 0.8530
  Attack Success Rate: 0.3419

============================================================
Round 14/20
  🔄 System stable. Increasing server learning rate to: 0.95
Attack Stage: 🌳 Mature Stage (Stable attacks)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 13 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 13 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.40% | Clean Test:  89.20% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.60% | Clean Test:  88.30% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.60% | Clean Test:  89.60% | ASR:   0.00%
  Client  3 (benign  ) | Local Train:  99.80% | Clean Test:  88.70% | ASR:   0.85%
  Client  4 (attacker) | Local Train:  99.80% | Clean Test:  77.50% | ASR:  76.07%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  77.40% | ASR:  72.65%

📈 Mean Performance:
  Benign Clients → Train:  99.60%, Clean:  88.95%
  Attackers      → Train:  99.90%, Clean:  77.45%, ASR:  74.36%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.558 ± 0.015
    Attacker 4 - Round 13:
    Amplification factor 放大因子: 3.7, beta: 0.5
    Norm 规范: 0.3677 -> 1.3925
    Direction preservation 方向保持: 0.9823
    Final similarity 最终相似度: -0.0336 (目标: 0.536)
    Difference from benign mean 与良性均值差异: 0.592
    Benign user similarity: 0.558 ± 0.015
    Attacker 5 - Round 13:
    Amplification factor 放大因子: 3.7, beta: 0.5
    Norm 规范: 0.3584 -> 1.3584
    Direction preservation 方向保持: 0.9814
    Final similarity 最终相似度: -0.0314 (目标: 0.536)
    Difference from benign mean 与良性均值差异: 0.590

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.138, Std Dev: 0.063
    Client 0 (Benign): 0.080
    Client 1 (Benign): 0.074
    Client 2 (Benign): 0.073
    Client 3 (Benign): 0.205
    Client 4 (Attacker): 0.200
    Client 5 (Attacker): 0.197
  📊 Update Stats: Accepted 4/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 33.3%

📊 Round 14 Results:
  Clean Accuracy: 0.7680
  Attack Success Rate: 0.7350
  ⚠️ ASR Change: +39.32%

============================================================
Round 15/20
Attack Stage: 🌳 Mature Stage (Stable attacks)
Current Parameters: server_lr=0.95, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 14 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 14 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.40% | Clean Test:  88.80% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.60% | Clean Test:  89.30% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.40% | Clean Test:  89.80% | ASR:   0.00%
  Client  3 (benign  ) | Local Train: 100.00% | Clean Test:  88.50% | ASR:   0.85%
  Client  4 (attacker) | Local Train:  99.80% | Clean Test:  79.90% | ASR:  65.81%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  80.80% | ASR:  57.26%

📈 Mean Performance:
  Benign Clients → Train:  99.60%, Clean:  89.10%
  Attackers      → Train:  99.90%, Clean:  80.35%, ASR:  61.54%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.629 ± 0.023
    Attacker 4 - Round 14:
    Amplification factor 放大因子: 3.8, beta: 0.5
    Norm 规范: 0.3328 -> 1.2962
    Direction preservation 方向保持: 0.9767
    Final similarity 最终相似度: -0.0099 (目标: 0.594)
    Difference from benign mean 与良性均值差异: 0.639
    Benign user similarity: 0.629 ± 0.023
    Attacker 5 - Round 14:
    Amplification factor 放大因子: 3.8, beta: 0.5
    Norm 规范: 0.3282 -> 1.2751
    Direction preservation 方向保持: 0.9792
    Final similarity 最终相似度: -0.0334 (目标: 0.594)
    Difference from benign mean 与良性均值差异: 0.662

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.182, Std Dev: 0.027
    Client 0 (Benign): 0.214
    Client 1 (Benign): 0.153
    Client 2 (Benign): 0.171
    Client 3 (Benign): 0.223
    Client 4 (Attacker): 0.173
    Client 5 (Attacker): 0.160
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.95 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.1290
  Rejection Rate: 0.0%

📊 Round 15 Results:
  Clean Accuracy: 0.8610
  Attack Success Rate: 0.2821
  ⚠️ ASR Change: -45.30%

============================================================
Round 16/20
  🔄 Large fluctuation detected. Lowering server learning rate to: 0.85
Attack Stage: 🔥 Late Stage (Sustained pressure)
Current Parameters: server_lr=0.85, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 15 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 15 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.80% | Clean Test:  89.20% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.80% | Clean Test:  88.80% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.40% | Clean Test:  89.60% | ASR:   0.85%
  Client  3 (benign  ) | Local Train: 100.00% | Clean Test:  88.90% | ASR:   0.00%
  Client  4 (attacker) | Local Train:  99.80% | Clean Test:  73.30% | ASR:  85.47%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  78.10% | ASR:  71.79%

📈 Mean Performance:
  Benign Clients → Train:  99.75%, Clean:  89.13%
  Attackers      → Train:  99.90%, Clean:  75.70%, ASR:  78.63%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.551 ± 0.012
    Attacker 4 - Round 15:
    Amplification factor 放大因子: 4.2, beta: 0.6
    Norm 规范: 0.3231 -> 1.3838
    Direction preservation 方向保持: 0.9718
    Final similarity 最终相似度: 0.0091 (目标: 0.545)
    Difference from benign mean 与良性均值差异: 0.542
    Benign user similarity: 0.551 ± 0.012
    Attacker 5 - Round 15:
    Amplification factor 放大因子: 4.2, beta: 0.6
    Norm 规范: 0.3057 -> 1.3117
    Direction preservation 方向保持: 0.9702
    Final similarity 最终相似度: 0.0098 (目标: 0.545)
    Difference from benign mean 与良性均值差异: 0.541

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.146, Std Dev: 0.052
    Client 0 (Benign): 0.079
    Client 1 (Benign): 0.160
    Client 2 (Benign): 0.076
    Client 3 (Benign): 0.155
    Client 4 (Attacker): 0.207
    Client 5 (Attacker): 0.200
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.855 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 0.0%

📊 Round 16 Results:
  Clean Accuracy: 0.8490
  Attack Success Rate: 0.3419

============================================================
Round 17/20
Attack Stage: 🔥 Late Stage (Sustained pressure)
Current Parameters: server_lr=0.85, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 16 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 16 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train: 100.00% | Clean Test:  89.00% | ASR:   0.85%
  Client  1 (benign  ) | Local Train:  99.80% | Clean Test:  87.90% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.60% | Clean Test:  89.00% | ASR:   0.00%
  Client  3 (benign  ) | Local Train: 100.00% | Clean Test:  88.40% | ASR:   0.00%
  Client  4 (attacker) | Local Train: 100.00% | Clean Test:  79.70% | ASR:  72.65%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  81.00% | ASR:  58.97%

📈 Mean Performance:
  Benign Clients → Train:  99.85%, Clean:  88.58%
  Attackers      → Train: 100.00%, Clean:  80.35%, ASR:  65.81%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.557 ± 0.038
    Attacker 4 - Round 16:
    Amplification factor 放大因子: 4.4, beta: 0.6
    Norm 规范: 0.3319 -> 1.4910
    Direction preservation 方向保持: 0.9826
    Final similarity 最终相似度: -0.0633 (目标: 0.538)
    Difference from benign mean 与良性均值差异: 0.620
    Benign user similarity: 0.557 ± 0.038
    Attacker 5 - Round 16:
    Amplification factor 放大因子: 4.4, beta: 0.6
    Norm 规范: 0.2804 -> 1.2684
    Direction preservation 方向保持: 0.9758
    Final similarity 最终相似度: -0.0334 (目标: 0.538)
    Difference from benign mean 与良性均值差异: 0.590

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.140, Std Dev: 0.071
    Client 0 (Benign): 0.069
    Client 1 (Benign): 0.072
    Client 2 (Benign): 0.067
    Client 3 (Benign): 0.207
    Client 4 (Attacker): 0.217
    Client 5 (Attacker): 0.208
  📊 Update Stats: Accepted 3/6 updates
  🔧 Server Learning Rate: 0.855 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 50.0%

📊 Round 17 Results:
  Clean Accuracy: 0.7790
  Attack Success Rate: 0.7607
  ⚠️ ASR Change: +41.88%

============================================================
Round 18/20
  🔄 Large fluctuation detected. Lowering server learning rate to: 0.77
Attack Stage: 🔥 Late Stage (Sustained pressure)
Current Parameters: server_lr=0.77, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 17 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 17 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.60% | Clean Test:  88.60% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.80% | Clean Test:  88.10% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.60% | Clean Test:  88.80% | ASR:   0.85%
  Client  3 (benign  ) | Local Train: 100.00% | Clean Test:  89.60% | ASR:   0.00%
  Client  4 (attacker) | Local Train: 100.00% | Clean Test:  81.50% | ASR:  56.41%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  78.70% | ASR:  72.65%

📈 Mean Performance:
  Benign Clients → Train:  99.75%, Clean:  88.77%
  Attackers      → Train: 100.00%, Clean:  80.10%, ASR:  64.53%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.692 ± 0.021
    Attacker 4 - Round 17:
    Amplification factor 放大因子: 4.6, beta: 0.6
    Norm 规范: 0.2869 -> 1.3546
    Direction preservation 方向保持: 0.9720
    Final similarity 最终相似度: -0.0280 (目标: 0.681)
    Difference from benign mean 与良性均值差异: 0.720
    Benign user similarity: 0.692 ± 0.021
    Attacker 5 - Round 17:
    Amplification factor 放大因子: 4.6, beta: 0.6
    Norm 规范: 0.2479 -> 1.1818
    Direction preservation 方向保持: 0.9628
    Final similarity 最终相似度: -0.0016 (目标: 0.681)
    Difference from benign mean 与良性均值差异: 0.694

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.237, Std Dev: 0.052
    Client 0 (Benign): 0.222
    Client 1 (Benign): 0.227
    Client 2 (Benign): 0.231
    Client 3 (Benign): 0.350
    Client 4 (Attacker): 0.197
    Client 5 (Attacker): 0.196
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.7695 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.1330
  Rejection Rate: 0.0%

📊 Round 18 Results:
  Clean Accuracy: 0.8520
  Attack Success Rate: 0.3333
  ⚠️ ASR Change: -42.74%

============================================================
Round 19/20
  🔄 Large fluctuation detected. Lowering server learning rate to: 0.69
Attack Stage: 🔥 Late Stage (Sustained pressure)
Current Parameters: server_lr=0.69, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 18 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 18 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train: 100.00% | Clean Test:  89.00% | ASR:   0.85%
  Client  1 (benign  ) | Local Train:  99.80% | Clean Test:  88.80% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.80% | Clean Test:  88.30% | ASR:   0.85%
  Client  3 (benign  ) | Local Train: 100.00% | Clean Test:  88.20% | ASR:   3.42%
  Client  4 (attacker) | Local Train: 100.00% | Clean Test:  72.30% | ASR:  88.89%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  76.20% | ASR:  76.92%

📈 Mean Performance:
  Benign Clients → Train:  99.90%, Clean:  88.58%
  Attackers      → Train: 100.00%, Clean:  74.25%, ASR:  82.91%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.577 ± 0.028
    Attacker 4 - Round 18:
    Amplification factor 放大因子: 4.7, beta: 0.6
    Norm 规范: 0.2834 -> 1.3646
    Direction preservation 方向保持: 0.9786
    Final similarity 最终相似度: -0.0642 (目标: 0.564)
    Difference from benign mean 与良性均值差异: 0.642
    Benign user similarity: 0.577 ± 0.028
    Attacker 5 - Round 18:
    Amplification factor 放大因子: 4.7, beta: 0.6
    Norm 规范: 0.2346 -> 1.1409
    Direction preservation 方向保持: 0.9691
    Final similarity 最终相似度: -0.0509 (目标: 0.564)
    Difference from benign mean 与良性均值差异: 0.628

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.152, Std Dev: 0.067
    Client 0 (Benign): 0.071
    Client 1 (Benign): 0.083
    Client 2 (Benign): 0.106
    Client 3 (Benign): 0.234
    Client 4 (Attacker): 0.217
    Client 5 (Attacker): 0.200
  📊 Update Stats: Accepted 5/6 updates
  🔧 Server Learning Rate: 0.69255 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 16.7%

📊 Round 19 Results:
  Clean Accuracy: 0.8350
  Attack Success Rate: 0.4274

============================================================
Round 20/20
Attack Stage: 🔥 Late Stage (Sustained pressure)
Current Parameters: server_lr=0.69, tolerance=2.0
============================================================
📡 Broadcasting the global model...

🔧 Phase 1: Client Preparation

Round 19 - Attacker 4 - Distribution: {'World': np.int64(111), 'Sports': np.int64(135), 'Business': np.int64(130), 'Sci/Tech': np.int64(124)}
  Progressive poisoning (rate=240.0%): 67/67 samples poisoned

Round 19 - Attacker 5 - Distribution: {'World': np.int64(119), 'Sports': np.int64(136), 'Business': np.int64(116), 'Sci/Tech': np.int64(129)}
  Progressive poisoning (rate=240.0%): 62/62 samples poisoned

💪 Phase 2: Local Training
  ✓ Client 0 completed training
  ✓ Client 1 completed training
  ✓ Client 2 completed training
  ✓ Client 3 completed training
    Attacker 4: Applying momentum (momentum=0.7)
  ✓ Client 4 completed training
    Attacker 5: Applying momentum (momentum=0.7)
  ✓ Client 5 completed training

🧪 Phase 2.5: Local Evaluation (per-client)

📊 Local Evaluation Summary (per-client):
  Client  0 (benign  ) | Local Train:  99.60% | Clean Test:  89.00% | ASR:   0.00%
  Client  1 (benign  ) | Local Train:  99.80% | Clean Test:  89.60% | ASR:   0.00%
  Client  2 (benign  ) | Local Train:  99.60% | Clean Test:  89.50% | ASR:   0.00%
  Client  3 (benign  ) | Local Train: 100.00% | Clean Test:  87.20% | ASR:   7.69%
  Client  4 (attacker) | Local Train: 100.00% | Clean Test:  73.70% | ASR:  80.34%
  Client  5 (attacker) | Local Train: 100.00% | Clean Test:  77.60% | ASR:  70.94%

📈 Mean Performance:
  Benign Clients → Train:  99.75%, Clean:  88.83%
  Attackers      → Train: 100.00%, Clean:  75.65%, ASR:  75.64%

🎭 Phase 3: Attacker Camouflage
    Benign user similarity: 0.576 ± 0.026
    Attacker 4 - Round 19:
    Amplification factor 放大因子: 4.8, beta: 0.6
    Norm 规范: 0.2324 -> 1.1558
    Direction preservation 方向保持: 0.9649
    Final similarity 最终相似度: -0.0428 (目标: 0.563)
    Difference from benign mean 与良性均值差异: 0.619
    Benign user similarity: 0.576 ± 0.026
    Attacker 5 - Round 19:
    Amplification factor 放大因子: 4.8, beta: 0.6
    Norm 规范: 0.1974 -> 0.9945
    Direction preservation 方向保持: 0.9524
    Final similarity 最终相似度: -0.0693 (目标: 0.563)
    Difference from benign mean 与良性均值差异: 0.645

🛡️ Phase 4: Defense and Aggregation
  📊 Using mixed similarity computation
  📈 Mixed Similarity - Mean: 0.161, Std Dev: 0.077
    Client 0 (Benign): 0.090
    Client 1 (Benign): 0.084
    Client 2 (Benign): 0.084
    Client 3 (Benign): 0.267
    Client 4 (Attacker): 0.235
    Client 5 (Attacker): 0.206
  📊 Update Stats: Accepted 6/6 updates
  🔧 Server Learning Rate: 0.69255 (Smooth updates)

📈 Defense Analysis:
  Dynamic Threshold: 0.0750
  Rejection Rate: 0.0%

📊 Round 20 Results:
  Clean Accuracy: 0.8330
  Attack Success Rate: 0.4701

Results saved to: results/progressive_grmp_progressive_semantic_poisoning.json

==================================================
Progressive GRMP Attack Analysis
==================================================

Attack Configuration:
  Total Clients: 6
  Attackers: 2 (33%)
  Base Poison Rate: 400%
  Total Rounds: 20
  Progressive Attack: Enabled

Progressive Attack Stages:

  Early (Trust Building):
    Avg Clean Accuracy: 0.8754
    Avg Attack Success: 0.0051
    Avg Detection Rate: 0.0%

  Growing (Increasing Impact):
    Avg Clean Accuracy: 0.8858
    Avg Attack Success: 0.0821
    Avg Detection Rate: 0.0%

  Mature (Strong Attack):
    Avg Clean Accuracy: 0.8382
    Avg Attack Success: 0.4051
    Avg Detection Rate: 0.0%

  Full Force (Maximum Impact):
    Avg Clean Accuracy: 0.8296
    Avg Attack Success: 0.4667
    Avg Detection Rate: 0.0%

Final Performance:
  Clean Accuracy: 0.8330
  Attack Success Rate: 0.4701
  Accuracy Drop: -0.30%

Attack Effectiveness:
  Peak ASR: 0.7607 (Round 17)
  Average Detection Rate: 0.0%

Attack Milestones:
  ASR ≥ 10%: First achieved in Round 10
  ASR ≥ 25%: First achieved in Round 11
  ASR ≥ 50%: First achieved in Round 14
  ASR ≥ 75%: First achieved in Round 17

==================================================
Progressive attack experiment completed!
==================================================
